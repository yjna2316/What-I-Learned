# Part1-2 Computer Architecture

* [폰노이만 구조](#폰노이만-구조)
* [CPU](#CPU)
  * [CPU 구조와 동작과정](#CPU-구조와-동작과정)
  * [파이프라이닝](#파이프라이닝)
    * [문제와 해결](#위험와-해결)
* [버스](#버스)
* [메모리](#메모리) 
  * [메모리 계층 구조](#메모리-계층-구조)
  * [캐시](#캐시)
    * [적중과 실패](#적중과-실패)
    * [지역성의 원리](지역성의-원리)
    * [캐시 블록 교체](#캐시-블록-교체)
    * [캐시 동기화 문제](#캐시-동기화-문제)
* [I/O 장치](#I/O장치)
  * [I/O 컨트롤러](#I/O-컨트롤러)
  * [I/O 동작 처리](#I/O-동작-처리)
    * [폴링](#폴링)
    * [인터럽트](#인터럽트)
    * [DMA](#DMA)
* [References](#reference)


## 폰노이만 구조
프로그램과 데이터가 하나의 메모리에 저장되는 구조로 기억장치에 저장된 순서대로 명령어가 실행된다. 현대 컴퓨터의 최초 버전이며 프로그램과 데이터가 서로 다른 메모리에 저장되는 건 하버드 구조이다. 

</br>

----------

현대 컴퓨터는 크게 명령어를 실행하는 CPU, 정보를 저장하는 MEMORY, 외부와의 연결을 담당하는 I/O장치(입출력 장치), 그리고 이들을 연결해주는 하나의 버스 구조로 구성되어 있다.


## CPU
**Overview** CPU란 명령어 실행이 이루어지는 컴퓨터의 한 부분으로 메모리에서 명령어를 읽어와 해석하고, 연산하고, 필요한 데이터를 메모리에서 읽고 쓰는 동작이 이루어지는 곳이다. 이러한 동작을 하기 위해 CPU 내부에는 연산을 담당하는 ALU, 명령어 해석과 제어를 담당하는 Control Unit, 데이터를 기억하는 여러 레지스터들과 이들을 연결하는 내부 버스가 필요하다. CPU의 명령어 처리 속도는 컴퓨터 성능에 영향을 주기 때문에 처리 속도를 높이기 위해 파이프라인 기술을 이용한다. 파이프라인 기술이란 공장의 생산라인처럼 명령어 처리 과정을 여러 단계로 나누어 서로 다른 명령어를 동시에 수행할 수 있는 기술이며, 명령어 처리율을 높일 수 있다. 하지만, 메모리 충돌 문제, 분기문 문제, 데이터 의존성 문제로 인해 이론상의 단계 수 만큼 속도가 정비례하지 않는다. 2개 이상의 파이프라인을 사용하여 그 파이프라인 수 만큼 명령어를 동시에 처리할 수 있는 기술로 슈퍼스칼라가 있다.

* **마이크로 연산**  각 클록 주기동안 실행되는 CPU 동작

### CPU 구조와 동작과정
CPU는 Program Counter(PC)에 저장되어 있는 명령어 주소에서 명령어를 읽어온다. 읽어온 명령어를 Control Unit에서 해석을 하고 ALU에서 필요한 연산을 한다. 연산 결과를 레지스터(AC)에 저장하고 필요한 데이터를 처리한다.

* PC(프로그램 카운터) : 다음에 실행할 명령어(instruction)의 주소를 가지고 있다. 
* IR(명령어 레지스터) : 현재 수행 중인 명령어를 가지고 있다.
* MAR(메모리 주소 레지스터) : 메모리로부터 읽어오거나 메모리에 쓰기 위한 주소를 가지고 있다.
* MBR(메모리 버퍼 레지스터) : 메모리로부터 읽어온 데이터 또는 메모리에 써야할 데이터를 가지고 있다.
* SP(스택 포인터): 스택의 끝을 가리킨다.

### 파이프라이닝과 문제
CPU 수행과정을 여러 단계로 나누어 각 단계가 서로 다른 명령어를 동시에 수행함으로써 CPU 처리율을 높이는 기술이다. 하지만, 

</br>

---------------------------------
## 버스
컴퓨터의 구성 요소들(CPU, 기억장치, I/O 장치)을 연결해주는 통로. 교환할 정보들을 전송하는 선(line)들로 구성. 버스 폭(선들의 수) = CPU와 기억장치 사이에 한번에 전송되는 비트 수 

**System Bus** CPU는 3개의 버스를 통해 메모리에 접근한다.

* **주소** CPU가 메모리의 어느 부분을 접근할지 나타낸다. 
* **데이터** 메모리에서 CPU로 데이터를 보내거나, CPU에서 메모리로 데이터를 보내는데 사용된다. 
* **제어신호** CPU가 메모리에 접근할지 안할지를 나타낸다. 

주소전달, 데이터 전달 버스에 어떤 값이 있다 하더라도 컨트롤 신호를 보내주지 않으면 CPU와 메모리는 아무런 일도 할 수 없다. 

**I/O Bus** 메모리와 입출력 장치를 통신하는 버스

**버스 중재** 하나의 버스를 사용하기 때문에 버스를 공유한다. 따라서 2개 이상의 요소가 동시에 버스 사용을 하려는 경우 순서를 결정해주는 동작이 필요하다.

</br>

-------------------------------------------------
## 메모리
### 메모리 계층 구조
메모리의 용량, 속도, 가격은 서로 상충되는 요소이기 때문에, 이를 극복하면서 CPU가 메모리에 빨리 접근(읽고 쓰는 동작)할 수 있도록 메모리를 계층적으로 사용해야 한다. 즉, 메모리 계층 구조란 작지만 빠른 메모리를 CPU에 가깝게 배치하고, 느리지만 대용량의 메모리를 CPU에 멀리 배치함으로써 가격 대비 성능을 높이는 구성 방식이다. 서로 인접한 계층에서만 데이터(복사본)를 전송하며 (CPU 하드디스크에 직접 접근 할 수 없다) 계층간 데이터 전송 단위는 서로 다르다.

Register > Cache > Main Memory(RAM) > Persistent Memory(SSD > HDD)

* RAM(Ramdom Access Memory): **휘발성**, Random Access란 어디든 똑같은 시간으로 접근이 가능하다는 의미. 
  * SRAM(Static RAM): 플립플롭 이용. 전원 공급 동안만 유지(캐시, 빠름)
  * DRAM(Dynamic RAM): 데이터 유지 위해 주기적 충전 필요(주기억)
  
* ROM(Read Only Memory): **영구적** 읽기만 가능. 삭제나 수정이 불가. 주기억 일부

* Register: 속도가 빠름. CPU 내부에서 사용하는 메모리로 CPU 동작의 중간 상태값들을 기억하기 위해 사용. 때문에 명령어 처리 과정을 독립적인 단계로 분할가능. 파이프라이닝 가능.

cf. CPU가 작은 메모리에 더 빨리 접근할 수 있는 이유는 메모리 용량이 커질 수록 디코딩 속도도 같이 커지기 때문이다.
레지스터와 캐시는 CPU 내부에 있기 때문에 CPU 외부에 있는 메모리보다 훨씬 빠르게 접근이 가능하다. 


## 캐시 
**Overview** CPU는 명령어 실행을 위해 메모리에서 데이터를 읽고 써야 한다. 하지만, 메모리의 속도가 느리기 때문에 CPU는 기다리게 되는 시간이 생기게 되고 이는 성능 저하에 영향을 준다. 따라서 CPU의 메모리 접근(읽고 쓰는 동작) 시간을 줄이고자 고속의 캐시 메모리를 사용하게 된다. 캐시가 이 역할을 잘 수행하기 위해서는 CPU가 찾을 법한 내용들을 **예측**할 수 있어야 한다. CPU가 찾는 내용이 많을수록 캐시에서 바로 읽어가면 되므로 시간이 단축되기 때문이다. 즉, 예측을 잘해야 **적중률**이 높아지고 캐시의 성능도 좋아진다. 예측을 위해 **지역성의 원리**를 이용한다. 지역성이란, 프로그램 특성상 메모리 내 모든 data가 골고루 사용되지 않고 특정 영역만 집중적을 참조되는 경향이다. 이러한 경향을 이용해 자주 쓰이는, 자주 쓰일 것 같은 data를 메모리에서 캐시로 읽어온다. 

* **캐싱** *데이터 접근 시간을 줄이기 위해* 접근 속도가 빠른 장치에 느린 장치의 *데이터를 미리 가져다 놓는 작업*


### 적중과 실패
캐시란 CPU 메모리 접근 시간을 단축하기 위한 고속의 메모리로 CPU 가까이에 위치하며 빈번하게 사용되는 데이터를 미리 가져다 두는 저장소이다. 캐시안에 CPU가 찾는 내용이 있을 확률을 적중률이라 하며, 찾는 내용이 캐시 안에 있다면 캐시 적중, 없다면 캐시 미스라 한다. 캐시 미스가 날 경우 메모리에서 해당 정보와 그와 인접한 정보를 함께 인출하여 캐시로 가져와야한다. (블록 단위) 


### 지역성 
지역성이란, 짧은 시간 동안 CPU가 기억장치의 특정 부분을 빈번하게 접근하는 현상을 말한다. 지역성이 생기는 이유는 반복문과 배열 형태의 자료구조를 들 수 있다. 코드가 루프를 수행하면 루프의 시작과 끝을 일정 횟수 이상 반복하므로 특정 코드 영역을 반복해서 접근한다. 이 때문에 코드에 대한 참조의 지역성이 생기게 된다. 배열도 마찬가지로, 배열을 정렬하기 위해 버블 정렬을 하거나, 이차원 배열로 이루어진 행렬의 곱을 구한다면 같은 메모리 영역을 계속 접근하게 될것이다. 따라서, **지역성이 클수록 캐시의 효과가 높아진다**. 지역성은 대표적으로 시간 지역성과 공간 지역성으로 나뉜다.

* **시간 지역성**: 최근에 참조된 데이터가 **가까운** 미래에 다시 참조되는 경향 ex) 반복문
  
* **공간 지역성**: 최근에 참조된 데이터에 **인접한** 데이터가 다시 참조되는 경향 ex) 배열 순회


### 캐시 블록 교체
캐시 메모리는 고가이기에 저용량을 사용한다. 만약 새로운 내용을 읽어와서 캐시에 저장하려 하는데 여유 공간이 없을 경우 기존의 캐시 블록 중 어느 것과 교체할지 결정해야 한다. 

* **LRU(Least Recently Used)** 가장 오랫동안 참조되지 않은 블록과 교체

* **FIFO(First In First Out)** 가장 오래된 블록과 교체 

* **LFU(Least Frequency Used)** 참조 횟수가 가장 적은 블록과 교체


### 캐시 동기화 문제
캐시와 메모리에서 데이터가 수정되면 이를 감지하고 갱신하는 방법이 필요하다. 대상의 정보가 변했음에도 불구하고 오래된 정보를 계속 가지고 있다면, 데이터가 일치하지 않아서 예기치 못한 상황이 발생할 수 있기 때문이다. 따라서 캐시의 내용을 적절히 동기화시켜 줘야 한다.

#### 캐시의 데이터가 수정될 경우 
**Write Through (즉시 쓰기)**
캐시된 데이터가 수정될 때마다 메모리도 즉시 갱신한다. 따라서 주기억장치의 내용들은 항상 유효(캐시 내용과 같다)하므로, 데이터 손실이 발생하면 안되는 데이터베이스 시스템과 같은 경우에 적합하다. 하지만 쓰기 동작을 할 때마다 메모리를 수정해야 하므로 속도가 느려지는 단점이 있다.
 
**Write Back (나중 쓰기)**
캐시까지만 수정하고 해당 캐시 블록이 교체될 때 메모리에 반영하는 방식으로, 수정 여부를 표시하기 위해 갱신 비트를 사용한다. 기억장치에 대한 쓰기 동작 횟수가 최소화 되므로 쓰기 속도가 빨라진다. 하지만, 입출력 장치가 데이터를 요청할 때 캐시와 메모리 중 어느 곳이 유효한 데이터를 제공할 수 있는지 살펴야 한다(예.DMA). 따라서 시스템이 다운되거나 전원이 나갈 경우, 캐시 안의 수정된 데이터를 잃을 수 있으므로 신뢰성보다 성능이 중요한 시스템에 적합하다.

#### 메모리가 수정될 경우
Invalidate: 메모리 내용이 변경되면 해당 캐시라인의 갱신 비트를 1로 쓴다. 캐시가 해당 정보를 참조할 때 갱신 비트를 확인하여 메모리에 있는 내용을 다시 읽어오도록 한다. 

Snooping(스누핑): 다중 주소 버스를 항상 감시하여 캐시 상의 메모리에 대한 접근이 있는지 감시하는 구조이다. 다른 캐시에서 쓰기가 발생하면 캐시 컨트롤러에 의해 자신의 캐시 위에 있는 복사본을 무효화시킨다.

cf. 웹 캐싱, 디스크 캐시, 다중코어 캐시 일관성

</br>

-------------------
## I/O 장치

## References
* 생능출판사, 컴퓨터구조론
* 한빛아카데미, 컴퓨터 아키텍처 컴퓨터 구조 및 동작 원리

