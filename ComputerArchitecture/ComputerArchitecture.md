# Part1-2 Computer Architecture

* [폰노이만 구조](#폰노이만-구조)
* [CPU](#CPU)
  * [논리 회로](#논리-회로)
  * [레지스터와 클록](#레지스터와-클록)
  * [CPU 구조](#CPU-구조)
  * [쉼 없이 일하라 - 파이프라이닝](#쉼-없이-일하라-파이프라이닝)
    * [위험과 해결](#위험과-해결)
* [버스](#버스)
* [메모리](#메모리) 
  * [메모리 계층 구조](#메모리-계층-구조)
  * [캐시](#캐시)
    * [적중과 실패](#적중과-실패)
    * [지역성의 원리](지역성의-원리)
    * [캐시 블록 교체](#캐시-블록-교체)
    * [캐시 동기화 문제](#캐시-동기화-문제)
* [입출력 장치](#입출력-장치)
  * [I/O 컨트롤러](#I/O-컨트롤러)
  * [I/O 동작 처리 방법](#I/O-동작-처리-방법)
    * [폴링](#폴링)
    * [인터럽트](#인터럽트)
    * [DMA(Direct Memory Access)](#DMA(Direct-Memory-Access))
* [References](#reference)


## 폰노이만 구조
프로그램과 데이터가 하나의 메모리에 저장되는 구조로 기억장치에 저장된 순서대로 명령어가 실행된다. 현대 컴퓨터의 최초 버전이며 프로그램과 데이터가 서로 다른 메모리에 저장되는 건 하버드 구조이다. 

</br>

----------

현대 컴퓨터는 크게 명령어를 실행하는 CPU, 정보를 저장하는 MEMORY, 외부와의 연결을 담당하는 I/O장치(입출력 장치), 그리고 이들을 연결해주는 하나의 버스 구조로 구성되어 있다.


## CPU
**Overview** CPU란 명령어 실행이 이루어지는 컴퓨터의 부분으로 메모리에서 명령어를 읽어와 해석하고, 연산하고, 필요한 데이터를 메모리에서 읽고 쓰는 동작이 이루어지는 곳이다. 이러한 동작을 하기 위해 CPU 내부에는 연산을 담당하는 ALU, 명령어 해석과 제어를 담당하는 Control Unit, 데이터를 기억하는 여러 레지스터들과 이들을 연결하는 내부 버스가 필요하다. CPU의 명령어 처리 속도는 컴퓨터 성능에 영향을 주기 때문에 처리 속도를 높이기 위해 파이프라인 기술을 이용한다. 파이프라인 기술이란 공장의 생산라인처럼 CPU 수행을 여러 단계로 나누어 각 단계를 한 클럭 동안 동시에 수행함으로써 명령어 처리율을 높이는 기술이다. 하지만, CPU 구조상의 문제, 분기문 문제, 데이터 의존성 문제로 인해 이론상의 단계 수 만큼 속도가 비례하진 않는다. 2개 이상의 파이프라인을 사용하여 그 파이프라인 수 만큼 명령어를 동시에 처리할 수 있는 기술인 슈퍼스칼라가 있다.

</br>

### 논리회로 
논리 회로는 크게 조합 논리 회로와 순차 논리 회로로 나눌 수 있다. 나누는 기준은 출력 값이 무엇에 의해 결정되는가이다. 

#### 조합 논리 회로
출력이 오직 입력값에 의해서만 결정된다. 입력이 동일하면 출력도 항상 동일하다. ex. 지하철 요금, 아무리 많은 사람이 타더라도 거리별 요금은 일정

#### 순차 논리 회로
출력이 입력값과 내부 상태값(메모리에 저장된 값)에 영향을 받는다. 상태값을 저장할 수 있는 플립플롭을 사용한다. 입력이 동일해도 출력이 달라질 수 있다. ex. 자판기에 돈 나눠서 넣기. 100원씩 넣을 때마다 새로 투입된 금액(100원)과 기존 금액을 더한  누계값이 다시 자판기의 입력값이 되어야함.

#### 플립플롭
플립플롭 역시 AND, OR 등의 게이트를 서로 연결해 만든 논리회로 중 하나. 단지 출력 값이 입력 쪽으로 사용되어 입력값이 바뀌어도 출력이 유지되는 메모리 효과를 지닌 논리회로이다. 이러한 플립플롭이 회로 구성 중에 사용되면 그 회로는 순차 논리회로가 된다.

</br>

### 레지스터와 클록
#### 클록(Clock) 
시계. 사람이 스케쥴에 맞추어 살아가게 되는 것처럼 CPU는 클록을 기준으로 정해진 시간에 주어진 동작을 하도록 설계됨

* **마이크로 연산**  각 클록 주기동안 실행되는 CPU 동작

#### 레지스터
CPU 내부 기억장치. CPU가 동작하면서 필요한 정보를 일시적으로 저장해 두는 장치이다. 곱셈시 계산의 중간 과정을 적어가면서 하는 것처럼, CPU도 중간의 상태 값을 기억하기 위해 빠른 기억 장치인 레지스터를 사용한다.

</br>

### CPU 구조
CPU는 Program Counter(PC)에 저장되어 있는 명령어 주소에서 명령어를 읽어온다. 읽어온 명령어를 Control Unit에서 해석을 하고 ALU에서 필요한 연산을 한다. 연산 결과를 레지스터(AC)에 저장하고 수행 과정에서 필요한 데이터를 읽고 쓴다.

* PC(프로그램 카운터) : 다음에 실행할 명령어(instruction)의 주소를 가지고 있다. 
* IR(명령어 레지스터) : 현재 수행 중인 명령어를 가지고 있다.
* MAR(메모리 주소 레지스터) : 메모리로부터 읽어오거나 메모리에 쓰기 위한 주소를 가지고 있다.
* MBR(메모리 버퍼 레지스터) : 메모리로부터 읽어온 데이터 또는 메모리에 써야할 데이터를 가지고 있다.
* SP(스택 포인터): 스택의 끝을 가리킨다.

</br>

### 쉼 없이 일하라 - 파이프라이닝
파이프라이닝(Pipelining)이란 핫도그를 만드는 과정에 비유할 수 있다. 핫도그 공장에서 핫도그를 대량 생산하기 위해 만드는 과정을 여러 단계로 쪼개서 분업을 시킨다. 즉, 한 사람은 빵만 올리고, 다음 사람은 그 위에 소세지를 얹고, 그 다음 사람은 그 위에 소스를 뿌리는 것이다. 그렇게 되면 동시에 여러개를 만들 수 있으므로 하나 만들고나서 또 하나를 만드는 것보다 더 빠르게 만들 수 있게 된다. 마찬가지로, CPU 수행 과정을 여러 단계로 나누어 각 단계를 동시에 처리하면 여러개 명령어를 더 빠르게 처리 할 수 있게 된다. 즉, **하나의 명령어 수행이 완전히 끝날 때까지 기다리지 않고 단계별로 나누어 한 클럭동안 동시에 수행함으로써 여러 명령어를 처리, CPU 처리율을 높이는 방법**이다. 이를 통해 단계 수만큼 CPU 처리 속도를 향상시킬 수 있다. 

#### 위험과 해결
하지만, 실제로는 이론만큼 속도가 나오진 않는다. 그 이유로 자원 동시 접근으로 인한 구조적인 위험, 이전 단계 결과값에 의존하는 데이터 위험, 중간에 처리 순서가 변경되는 분기문 위험이 있다.

1. **구조적인 위험**
실행중인 2개 이상의 명령어가 동일한 하드웨어 자원을 동시에 필요로 할 때 발생. 명령어 인출 단계와 데이터를 읽고 쓰는 단계는 모두 메모리에 접근해야 한다. 하지만 파이프라이닝은 각 단계가 동시에 수행되기 때문에 동시에 메모리 접근을 하게 되고, 메모리는 동시 접근이 불가능하므로 한쪽은 기다리게 된다. 해결책으로 같은 하드웨어를 사용하는 단계끼리 충돌이 발생하지 않도록 명령어와 데이터 메모리를 따로 분리시키는 방법이 있다. 이는 명령어와 데이터간에 연관성이 없기 때문에 가능하다.

2. **데이터 위험**
이전 단계의 명령어 결과값을 가지고 다음 단계의 명령어를 수행할 수 있는 상황으로 연산할 데이터가 준비되지 않아서 지체 되는 상황이다. 해결 방법으로 데이터 포워딩이 있다. 즉, 각 단계의 출력값을 다른 단계의 입력값으로 바로 전송(포워딩)해 줄 수 있는 경로를 만들어 준다.

3. **분기 위험**
분기 명령어로 인해 실행 순서가 갑자기 변경되는 상황을 말한다. 파이프라이닝으로 미리 인출되어 처리되고 있던 명령어는 무효화되고 그만큼의 사이클이 낭비 된다. 이를 해결하기 위해 분기를 미리 예측하여 어느 명령어를 인출할지 결정하거나, 조건 분기가 인식되면 분기 명령어 다음 명령어와 조건 만족시 분기하게 될 목적지 명령어도 함께 인출하는 방법이 있다. 후자의 경우 별도의 저장소가 필요하다.
</br>

------------------------------------------------
## 버스
컴퓨터의 구성 요소들(CPU, 기억장치, I/O 장치)을 연결해주는 통로. 교환할 정보들을 전송하는 선(line)들로 구성. 버스 폭(선들의 수) = CPU와 기억장치 사이에 한번에 전송되는 비트 수 

**System Bus** CPU는 3개의 버스를 통해 메모리에 접근한다.

* **주소** CPU가 메모리의 어느 부분을 접근할지 나타낸다. 
* **데이터** 메모리에서 CPU로 데이터를 보내거나, CPU에서 메모리로 데이터를 보내는데 사용된다. 
* **제어신호** CPU가 메모리에 접근할지 안할지를 나타낸다. 

주소전달, 데이터 전달 버스에 어떤 값이 있다 하더라도 컨트롤 신호를 보내주지 않으면 CPU와 메모리는 아무런 일도 할 수 없다. 

* **I/O Bus** 메모리와 입출력 장치를 통신하는 버스

* **버스 중재** 하나의 버스를 사용하기 때문에 버스를 공유한다. 따라서 2개 이상의 요소가 동시에 버스 사용을 하려는 경우 순서를 결정해주는 동작이 필요하다.

</br>

-------------------------------------------------
## 메모리
### 메모리 계층 구조
메모리의 용량, 속도, 가격은 서로 상충되는 요소이기 때문에, 이를 극복하면서 CPU가 메모리에 빨리 접근(읽고 쓰는 동작)할 수 있도록 메모리를 계층적으로 사용해야 한다. 즉, 메모리 계층 구조란 작지만 빠른 메모리를 CPU에 가깝게 배치하고, 느리지만 대용량의 메모리를 CPU에 멀리 배치함으로써 가격 대비 성능을 높이는 구성 방식이다. 서로 인접한 계층에서만 데이터(복사본)를 전송하며 (CPU 하드디스크에 직접 접근 할 수 없다) 계층간 데이터 전송 단위는 서로 다르다.

Register > Cache(내부 L1 > 외부 L2) > Main Memory(RAM) > Persistent Memory(SSD > HDD)

* RAM(Ramdom Access Memory): **휘발성**, Random Access란 어디든 똑같은 시간으로 접근이 가능하다는 의미. 
  * SRAM(Static RAM): 플립플롭 이용. 전원 공급 동안만 유지(캐시, 빠름)
  * DRAM(Dynamic RAM): 데이터 유지 위해 주기적 충전 필요(주기억)
  
* ROM(Read Only Memory): **영구적** 읽기만 가능. 삭제나 수정이 불가. 주기억 일부

* Register: 속도가 빠름. CPU 내부에서 사용하는 메모리로 CPU 동작의 중간 상태값들을 기억하기 위해 사용. 때문에 명령어 처리 과정을 독립적인 단계로 분할가능. 파이프라이닝 가능.

cf. CPU가 작은 메모리에 더 빨리 접근할 수 있는 이유는 메모리 용량이 커질 수록 디코딩 시간도 같이 커지기 때문이다.
레지스터와 캐시는 CPU 내부에 있기 때문에 CPU 외부에 있는 메모리보다 훨씬 빠르게 접근이 가능하다. 


## 캐시 
**Overview** CPU는 명령어 실행을 위해 메모리에서 데이터를 읽고 써야 한다. 하지만, 메모리의 속도가 느리기 때문에 CPU는 기다리게 되는 시간이 생기게 되고 이는 성능 저하에 영향을 준다. 따라서 CPU의 메모리 접근(읽고 쓰는 동작) 시간을 줄이고자 고속의 캐시 메모리를 사용하게 된다. 캐시가 이 역할을 잘 수행하기 위해서는 CPU가 찾을 법한 내용들을 **예측**할 수 있어야 한다. CPU가 찾는 내용이 많을수록 캐시에서 바로 읽어가면 되므로 시간이 단축되기 때문이다. 즉, 예측을 잘해야 **적중률**이 높아지고 캐시의 성능도 좋아진다. 예측을 위해 **지역성의 원리**를 이용한다. 지역성이란, 프로그램 특성상 메모리 내 모든 data가 골고루 사용되지 않고 특정 영역만 집중적을 참조되는 경향이다. 이러한 경향을 이용해 자주 쓰이는, 자주 쓰일 것 같은 data를 메모리에서 캐시로 읽어온다. 

* **캐싱** **데이터 접근 시간을 줄이기 위해** 접근 속도가 빠른 장치에 느린 장치의 **데이터를 미리 가져다 놓는 작업**


### 적중과 실패
캐시란 CPU 메모리 접근 시간을 단축하기 위한 고속의 메모리로 CPU 가까이에 위치하며 빈번하게 사용되는 데이터를 미리 가져다 두는 저장소이다. 캐시안에 CPU가 찾는 내용이 있을 확률을 적중률이라 하며, 찾는 내용이 캐시 안에 있다면 캐시 적중, 없다면 캐시 미스라 한다. 캐시 미스가 날 경우 메모리에서 해당 정보와 그와 인접한 정보를 함께 인출하여 캐시로 가져와야한다. (블록 단위) 


### 지역성 
지역성이란, 짧은 시간 동안 CPU가 기억장치의 특정 부분을 빈번하게 접근하는 현상을 말한다. 지역성이 생기는 이유는 반복문과 배열 형태의 자료구조를 들 수 있다. 코드가 루프를 수행하면 루프의 시작과 끝을 일정 횟수 이상 반복하므로 특정 코드 영역을 반복해서 접근한다. 이 때문에 코드에 대한 참조의 지역성이 생기게 된다. 배열도 마찬가지로, 배열을 정렬하기 위해 버블 정렬을 하거나, 이차원 배열로 이루어진 행렬의 곱을 구한다면 같은 메모리 영역을 계속 접근하게 될것이다. 따라서, **지역성이 클수록 캐시의 효과가 높아진다**. 지역성은 대표적으로 시간 지역성과 공간 지역성으로 나뉜다.

* **시간 지역성**: 최근에 참조된 데이터가 **가까운** 미래에 다시 참조되는 경향 ex) 반복문
  
* **공간 지역성**: 최근에 참조된 데이터에 **인접한** 데이터가 다시 참조되는 경향 ex) 배열 순회


### 캐시 블록 교체
캐시 메모리는 고가이기에 저용량을 사용한다. 만약 새로운 내용을 읽어와서 캐시에 저장하려 하는데 여유 공간이 없을 경우 기존의 캐시 블록 중 어느 것과 교체할지 결정해야 한다. 

* **LRU(Least Recently Used)** 가장 오랫동안 참조되지 않은 블록과 교체

* **FIFO(First In First Out)** 가장 오래된 블록과 교체 

* **LFU(Least Frequency Used)** 참조 횟수가 가장 적은 블록과 교체


### 캐시 동기화 문제
캐시와 메모리에서 데이터가 수정되면 이를 감지하고 갱신하는 방법이 필요하다. 대상의 정보가 변했음에도 불구하고 오래된 정보를 계속 가지고 있다면, 데이터가 일치하지 않아서 예기치 못한 상황이 발생할 수 있기 때문이다. 따라서 캐시의 내용을 적절히 동기화시켜 줘야 한다.

#### 캐시의 데이터가 수정될 경우 
**Write Through (즉시 쓰기)**
캐시된 데이터가 수정될 때마다 메모리도 즉시 갱신한다. 따라서 주기억장치의 내용들은 항상 유효(캐시 내용과 같다)하므로, 데이터 손실이 발생하면 안되는 데이터베이스 시스템과 같은 경우에 적합하다. 하지만 쓰기 동작을 할 때마다 메모리를 수정해야 하므로 속도가 느려지는 단점이 있다.
 
**Write Back (나중 쓰기)**
캐시까지만 수정하고 해당 캐시 블록이 교체될 때 메모리에 반영하는 방식으로, 수정 여부를 표시하기 위해 갱신 비트를 사용한다. 기억장치에 대한 쓰기 동작 횟수가 최소화 되므로 쓰기 속도가 빨라진다. 하지만, 입출력 장치가 데이터를 요청할 때 캐시와 메모리 중 어느 곳이 유효한 데이터를 제공할 수 있는지 살펴야 한다(예.DMA). 따라서 시스템이 다운되거나 전원이 나갈 경우, 캐시 안의 수정된 데이터를 잃을 수 있으므로 신뢰성보다 성능이 중요한 시스템에 적합하다.

#### 메모리가 수정될 경우
Invalidate: 메모리 내용이 변경되면 해당 캐시라인의 갱신 비트를 1로 쓴다. 캐시가 해당 정보를 참조할 때 갱신 비트를 확인하여 메모리에 있는 내용을 다시 읽어오도록 한다. 

Snooping(스누핑): 다중 주소 버스를 항상 감시하여 캐시 상의 메모리에 대한 접근이 있는지 감시하는 구조이다. 다른 캐시에서 쓰기가 발생하면 캐시 컨트롤러에 의해 자신의 캐시 위에 있는 복사본을 무효화시킨다.

cf. 웹 캐싱, 디스크 캐시, 다중코어 캐시 일관성

</br>

-------------------
## 입출력 장치
### I/O 컨트롤러
I/O 장치들은 종류에 따라 제어 방법이 다르고 데이터 전송 속도가 CPU 데이터 처리 속도에 비해 매우 느리기 때문에 CPU와 I/O 장치간 인터페이스 역할을 하는 I/O 컨트롤러를 사용한다. 따라서, CPU는 I/O장치에 직접 접근이 불가능하며 컨트롤러를 통해 통신한다.

### I/O 동작 처리 방법
그렇다면 CPU는 입출력 장치와 관련된 동작들을 어떻게 처리할 수 있을까? 
#### 폴링 
CPU가 반복적으로 I/O 상태(컨트롤러의 레지스터)를 검사하면서 I/O 동작을 처리하는 방식. 간단하고 별도의 하드웨어가 필요하지 않지만, CPU가 I/O 동작에 직접 관여해야 하므로 그 동안 다른 일을 하지 못한다.

#### 인터럽트
인터럽트 메커니즘을 이용해 I/O 동작이 진행되는 동안 CPU는 다른 작업을 처리할 수 있는 방식. 하지만 I/O장치와 Memory 사이의 모든 데이터 이동은 CPU를 경유해야 하므로 CPU가 어느정도는 관여하게 된다. 예로, Memory 데이터를 I/O 장치에 저장할 때, 경로는 메모리 -> I/O 장치가 아니라 메모리 -> CPU -> I/O 장치가 된다. 따라서 데이터의 크기가 클수록 CPU 시간은 소모되고 시스템 버스는 점유된다. 

#### DMA(Direct Memory Access)
CPU 개입 없이 I/O 장치와 Memory 사이에 데이터를 전송하는 방식. CPU가 주기억장치를 접근하지 않는 시간(CPU가 내부적으로 명령어를 해독하거나 ALU 연산을 수행하는 시간) 동안에 시스템 버스를 사용해 일을 한다. 따라서 CPU는 필요한 I/O 정보를 포함한 명령을 DMA에게 보내면 다른 작업을 할 수 있게 된다. 

## References
* 생능출판사, 컴퓨터구조론
* 한빛아카데미, 컴퓨터 아키텍처 컴퓨터 구조 및 동작 원리
* 한빛미디어, 뇌를 자극하는 프로그래밍 원리 CPU부터 OS까지

